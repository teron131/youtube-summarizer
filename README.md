# YouTube Summarizer Backend API

A comprehensive Python backend API for YouTube video analysis with AI-powered transcription and summarization. Built with FastAPI and featuring a robust multi-tier processing architecture for maximum reliability.

## üåü Key Features

- **üéØ Master API Endpoint**: Single `/api/generate` endpoint orchestrating all processing capabilities
- **üîÑ Multi-Tier Processing**: Apify scraper ‚Üí yt-dlp + Fal.ai ‚Üí LangGraph AI workflow
- **üé§ Smart Transcription**: Prioritizes Apify transcript, falls back to yt-dlp + Fal.ai transcription
- **ü§ñ AI Summarization**: LangGraph-powered self-checking workflow with dual AI provider support
- **üìä Comprehensive APIs**: Granular endpoints for specific tasks plus master orchestrator
- **üõ°Ô∏è Robust Error Handling**: Graceful degradation with detailed logging
- **‚ö° High Performance**: FastAPI with async processing and optimized audio handling

## üèóÔ∏è Architecture & Workflow

### üìä Overall System Architecture

```mermaid
graph TD
    A[YouTube URL] --> B[Validate URL]
    B --> C[Apify Scraper<br/>üìã Extract Video Data]
    C --> D[Get Transcript<br/>üìù Direct from YouTube]
    D --> E{Transcript Available?}
    E -->|Yes| F[LangGraph AI Workflow<br/>üîÑ Self-Checking Analysis]
    E -->|No| G[Download Audio<br/>üéµ yt-dlp]
    G --> H[Transcribe Audio<br/>üé§ Fal.ai API]
    H --> F
    F --> I[Return Complete Results]
    
    style A fill:#424242,color:#fff
    style B fill:#424242,color:#fff
    style C fill:#1E88E5,color:#fff
    style D fill:#1E88E5,color:#fff
    style E fill:#424242,color:#fff
    style G fill:#F9A825,color:#000
    style H fill:#F9A825,color:#000
    style F fill:#2E7D32,color:#fff
    style I fill:#424242,color:#fff
```

### üîÑ LangGraph AI Workflow Detail

The heart of our system is a sophisticated LangGraph workflow that ensures high-quality analysis through iterative refinement:

```mermaid
graph TD
    START([Start]) --> ROUTE{Input Type?}
    ROUTE -->|YouTube URL| GA[Gemini Analysis<br/>ü§ñ Direct URL Processing]
    ROUTE -->|Text/Transcript| LA[LangChain Analysis<br/>ü§ñ Text Processing]
    
    GA --> GQ[Gemini Quality Check<br/>üìä Aspects Assessment]
    LA --> LQ[LangChain Quality Check<br/>üìä Aspects Assessment]
    
    GQ --> GC{Quality >= Thresholdx<br/>OR Max Iterations?}
    LQ --> LC{Quality >= Threshold<br/>OR Max Iterations?}
    
    GC -->|No| GR[Gemini Refinement<br/>üîß Improve Analysis]
    LC -->|No| LR[LangChain Refinement<br/>üîß Improve Analysis]
    
    GR --> GQ
    LR --> LQ
    
    GC -->|Yes| END([Final Analysis])
    LC -->|Yes| END
    
    style START fill:#424242,color:#fff
    style ROUTE fill:#424242,color:#fff
    style GA fill:#8E24AA,color:#fff
    style LA fill:#8E24AA,color:#fff
    style GQ fill:#D84315,color:#fff
    style LQ fill:#D84315,color:#fff
    style GC fill:#424242,color:#fff
    style LC fill:#424242,color:#fff
    style GR fill:#26C6DA,color:#000
    style LR fill:#26C6DA,color:#000
    style END fill:#424242,color:#fff
```

**üé® Color Legend:**
- üîµ **Blue**: Apify Scraper (metadata & transcript extraction)
- üü† **Amber**: Fallback processing (yt-dlp + Fal.ai transcription)
- üü£ **Purple**: AI Analysis (Gemini/LangChain)
- üü• **Deep Orange**: Quality Assessment
- üü¢ **Dark Green**: LangGraph Final Processing
- üî∑ **Cyan**: Refinement steps (improve analysis)
- ‚ö´ **Dark Gray**: Decision points & flow control

### üß† LangGraph Workflow Features

- **üéØ Dual AI Provider Support**: Automatically routes between Gemini SDK (for YouTube URLs) and LangChain (for text)
- **üîÑ Iterative Refinement**: Quality checking with optional improvement cycles
- **‚ö° Streaming Support**: Real-time progress updates through workflow states

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- FFmpeg (for audio processing fallback)
- API Keys: `APIFY_API_KEY`, `GEMINI_API_KEY`, `FAL_KEY`, `OPENROUTER_API_KEY` (optional)

### 1. Installation

```bash
git clone <repository-url>
cd youtube-summarizer

# Install with UV (recommended)
uv sync

# Or with pip
pip install -r requirements.txt

# Install as editable package
uv pip install -e .
```

### 2. Environment Configuration

```bash
# Copy example environment file
cp .env_example .env

# Edit .env with your API keys
```

Required environment variables:
```env
APIFY_API_KEY=your_apify_api_key
GEMINI_API_KEY=your_gemini_api_key
FAL_KEY=your_fal_api_key
OPENROUTER_API_KEY=your_openrouter_api_key  # Optional
PORT=8080
HOST=0.0.0.0
```

### 3. Start the API Server

```bash
# Development mode
python app.py

# Or using uvicorn directly
python -m uvicorn app:app --host 0.0.0.0 --port 8080

# Production mode
./start.sh
```

### 4. Access the API

- **API Server**: http://localhost:8080
- **Interactive Documentation**: http://localhost:8080/api/docs
- **Alternative Docs**: http://localhost:8080/api/redoc
- **Health Check**: http://localhost:8080/api/health

## üéØ Complete API Reference

### üåü Master Endpoint

#### POST `/scrap` - Video Scraping and Transcript Extraction
**Extract video metadata and transcript using Apify scraper**

**Request:**
```json
{
  "url": "https://www.youtube.com/watch?v=VIDEO_ID"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Video scraped successfully",
  "url": "https://www.youtube.com/watch?v=VIDEO_ID",
  "title": "Video Title",
  "author": "Channel Name",
  "transcript": "Full transcript text with chapter formatting...",
  "duration": "00:06:32",
  "thumbnail": "https://img.youtube.com/vi/VIDEO_ID/maxresdefault.jpg",
  "view_count": 13462116,
  "processing_time": "7.5s",
  "timestamp": "2025-01-01T12:00:00.000Z"
}
```

### üìã Analysis Endpoints

#### POST `/summarize` - LangGraph Analysis
Generate AI summary from provided text content using LangGraph workflow.

**Request:**
```json
{
  "content": "Long text content to summarize...",
  "content_type": "transcript"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Analysis completed successfully",
  "analysis": {
    "title": "Extracted Title",
    "summary": "Comprehensive summary...",
    "takeaways": ["Key insight 1", "Key insight 2"],
    "key_facts": ["Important fact 1", "Important fact 2"],
    "chapters": [
      {
        "header": "Chapter Title",
        "summary": "Chapter content...",
        "key_points": ["Point 1", "Point 2"]
      }
    ],
    "keywords": ["keyword1", "keyword2", "keyword3"]
  },
  "quality": null,
  "processing_time": "15.2s",
  "iteration_count": 1,
  "timestamp": "2025-01-01T12:00:00.000Z"
}
```

#### POST `/stream-summarize` - Streaming Analysis
Real-time streaming updates of the LangGraph workflow progress.

**Request:**
```json
{
  "content": "Long text content to summarize...",
  "content_type": "transcript"
}
```

**Response Stream (Server-Sent Events):**
```json
// Initial status
data: {"type": "status", "message": "Starting analysis...", "timestamp": "2025-01-01T12:00:00.000Z"}

// Workflow progress updates
data: {"transcript_or_url": "content...", "analysis": null, "quality": null, "iteration_count": 0, "is_complete": false, "timestamp": "2025-01-01T12:00:01.000Z", "chunk_number": 0}

data: {"transcript_or_url": "content...", "analysis": {...}, "quality": {"percentage_score": 85}, "iteration_count": 1, "is_complete": false, "timestamp": "2025-01-01T12:00:15.000Z", "chunk_number": 1}

// Final completion
data: {"type": "complete", "message": "Analysis completed", "processing_time": "25.3s", "total_chunks": 3, "timestamp": "2025-01-01T12:00:25.000Z"}
```

#### GET `/health` - Health Check
System status and API availability with environment configuration.

**Response:**
```json
{
  "status": "healthy",
  "message": "YouTube Summarizer API is running",
  "timestamp": "2025-01-01T12:00:00.000Z",
  "version": "3.0.0",
  "environment": {
    "gemini_configured": true,
    "apify_configured": true
  }
}
```

## üîÑ Processing Architecture

### Tier 1: Apify YouTube Scraper
- **Primary Method**: Direct transcript and metadata extraction via Apify API
- **Data Extracted**: Title, author, duration, view count, thumbnail, full transcript with timestamps
- **Chapter Support**: Automatic chapter detection and transcript organization
- **Fallback**: yt-dlp audio download + Fal.ai transcription when transcript unavailable

### Tier 2: LangGraph AI Analysis
- **Method**: Dual-provider AI processing with quality assessment
- **Gemini Path**: Direct YouTube URL processing for maximum context
- **LangChain Path**: Text-based analysis with OpenRouter model access
- **Quality Control**: Automated quality checking with iterative refinement

### Tier 3: Graceful Degradation
- **Method**: Partial processing with available components
- **Error Handling**: Detailed logging and user-friendly error messages

## üîÑ LangGraph AI Workflow Architecture

### üéØ Core Components

The LangGraph workflow implements a sophisticated self-checking analysis system with the following components:

#### üìä Quality Assessment Framework
- Evaluates analysis completeness, structure, grammar, timestamps, content filtering, and language consistency

#### üîÄ Dual Processing Paths

**ü§ñ Gemini Path (YouTube URLs)**
- Direct URL processing using Gemini SDK
- File URI integration for efficient video analysis
- Thinking capabilities with configurable budget
- Native structured output with Pydantic schemas

**üîó LangChain Path (Text/Transcripts)**
- OpenRouter API integration for flexible model access
- Prompt templates for consistent analysis structure
- Structured output parsing with validation
- Support for multiple LLM providers

#### ‚öôÔ∏è Workflow Configuration

```python
# Global workflow settings
ANALYSIS_MODEL = "google/gemini-2.5-flash-lite"
QUALITY_MODEL = "google/gemini-2.5-pro"
MIN_QUALITY_SCORE = 90  # 90% quality threshold
MAX_ITERATIONS = 2      # Maximum refinement cycles
```

#### üîÑ Processing States

```python
class WorkflowState(BaseModel):
    # Input
    transcript_or_url: str
    
    # Analysis results
    analysis: Optional[Analysis] = None
    quality: Optional[Quality] = None
    
    # Control fields
    iteration_count: int = Field(default=0)
    is_complete: bool = Field(default=False)
```

### üöÄ Workflow Execution

#### Standard Processing
```python
from youtube_summarizer.summarizer import summarize_video

# Single execution with final result
analysis = summarize_video("https://www.youtube.com/watch?v=VIDEO_ID")
print(f"Quality Score: {analysis.quality_score}%")
```

#### Streaming Processing
```python
from youtube_summarizer.summarizer import stream_summarize_video

# Real-time progress updates
for state in stream_summarize_video("transcript text"):
    print(f"Iteration {state.iteration_count}: {state.quality.percentage_score if state.quality else 'Processing'}%")
```

### üîß Technical Implementation Details

#### Node Functions
- **`langchain_or_gemini()`**: Routes input based on type (URL vs text)
- **`*_analysis_node()`**: Initial AI analysis generation
- **`*_quality_node()`**: Quality assessment and scoring
- **`*_refinement_node()`**: Iterative improvement based on feedback
- **`should_continue_*()`**: Conditional routing for workflow control

#### Graph Structure
```python
# Conditional routing from START
builder.add_conditional_edges(
    START,
    langchain_or_gemini,
    {
        "langchain_analysis": "langchain_analysis",
        "gemini_analysis": "gemini_analysis",
    },
)

# Quality-based refinement loops
builder.add_conditional_edges(
    "gemini_quality",
    should_continue_gemini,
    {
        "gemini_refinement": "gemini_refinement",
        END: END,
    },
)
```

### üìà Processing Configuration

- **Quality Threshold**: 90% minimum score for acceptance
- **Max Iterations**: 2 refinement cycles maximum
- **Processing Time**: 15-45 seconds depending on content complexity

## üõ†Ô∏è Development

### Package Usage

```python
from youtube_summarizer.youtube_scrapper import scrap_youtube
from youtube_summarizer.summarizer import summarize_video, stream_summarize_video
from youtube_summarizer.utils import is_youtube_url, clean_youtube_url

# Video scraping with Apify
result = scrap_youtube("https://www.youtube.com/watch?v=VIDEO_ID")
print(result.title, result.author, len(result.transcript))

# AI summarization (LangGraph workflow)
analysis = summarize_video("transcript content or YouTube URL")

# Streaming analysis with progress updates
for state in stream_summarize_video("transcript content"):
    print(f"Iteration {state.iteration_count}, Complete: {state.is_complete}")

# URL utilities
is_valid = is_youtube_url(url)
clean_url = clean_youtube_url(url)
```

### Running Tests

```bash
# Install development dependencies
uv add --dev pytest black ruff

# Run tests
pytest

# Format code
black .

# Lint code
ruff check .
```

## üîß Configuration

### Environment Variables

| Variable | Required | Description | Default |
|----------|----------|-------------|---------|
| `APIFY_API_KEY` | ‚úÖ | Apify API key for YouTube scraping | - |
| `GEMINI_API_KEY` | ‚úÖ | Google Gemini API key for AI analysis | - |
| `FAL_KEY` | ‚úÖ | Fal.ai API key for audio transcription fallback | - |
| `OPENROUTER_API_KEY` | ‚ùå | OpenRouter API key for LangChain models | - |
| `PORT` | ‚ùå | Server port | 8080 |
| `HOST` | ‚ùå | Server host | 0.0.0.0 |

### Core Dependencies

- **FastAPI**: Web framework with automatic API documentation
- **requests**: HTTP client for Apify API integration
- **yt-dlp**: Video downloader for audio extraction fallback
- **google-genai**: Google Gemini AI client for direct URL processing
- **langchain**: LLM framework for flexible AI provider integration
- **langgraph**: Workflow orchestration for analysis pipeline
- **fal-client**: Audio transcription service
- **pydantic**: Data validation and settings management
- **uvicorn**: ASGI server

## üìä Performance & Processing

### Processing Times
- **Apify Scraping**: 5-15 seconds (metadata + transcript extraction)
- **Audio Transcription**: 30-60 seconds (yt-dlp + Fal.ai fallback)
- **LangGraph AI Analysis**: 15-45 seconds (with quality checking)
- **Complete Processing**: 20-90 seconds total depending on method

### Error Handling
- Comprehensive logging for debugging
- Step-by-step processing status tracking
- Graceful degradation when components fail

## üîç Troubleshooting

### Common Issues

**FFmpeg not found:**
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian  
sudo apt update && sudo apt install ffmpeg

# Windows - Download from https://ffmpeg.org/
```

**API Key Configuration:**
```bash
# Check your .env file
cat .env

# Ensure keys are set
echo $APIFY_API_KEY
echo $GEMINI_API_KEY
echo $FAL_KEY
echo $OPENROUTER_API_KEY
```

**Import Errors:**
```bash
# Install in editable mode
uv pip install -e .

# Verify installation
python -c "import youtube_summarizer; print('OK')"
```

**Processing Failures:**
- Check logs in API response for detailed error information
- Verify video is publicly accessible and not age-restricted
- Ensure API keys have sufficient credits
- Test with `/health` endpoint to verify API configuration
